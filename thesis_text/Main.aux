\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{ynt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Figures}{xi}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Tables}{xiii}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is reinforcement learning?}{1}{section.1.1}\protected@file@percent }
\newlabel{sec-what-is-rl}{{1.1}{1}{What is reinforcement learning?}{section.1.1}{}}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Why is reinforcement learning interesting?}{2}{section.1.2}\protected@file@percent }
\newlabel{sec-why-is-rl-interesting}{{1.2}{2}{Why is reinforcement learning interesting?}{section.1.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Efforts in making reinforcement learning more efficient}{2}{section.1.3}\protected@file@percent }
\newlabel{efforts-in-making-rl-efficient}{{1.3}{2}{Efforts in making reinforcement learning more efficient}{section.1.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.4}Goal of the thesis}{3}{section.1.4}\protected@file@percent }
\newlabel{sec-thesis-goal}{{1.4}{3}{Goal of the thesis}{section.1.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Hypothesis}{4}{subsection.1.4.1}\protected@file@percent }
\newlabel{subsec-hypothesis}{{1.4.1}{4}{Hypothesis}{subsection.1.4.1}{}}
\newlabel{parallel-training-hypothesis}{{1}{4}{Hypothesis}{Item.1}{}}
\newlabel{good-features-hypothesis}{{2}{4}{Hypothesis}{Item.2}{}}
\newlabel{regularization-hypothesis}{{3}{4}{Hypothesis}{Item.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Contributions}{5}{subsection.1.4.2}\protected@file@percent }
\newlabel{subsec-contributions}{{1.4.2}{5}{Contributions}{subsection.1.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.5}Outline}{5}{section.1.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Reinforcement learning}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-rl-background}{{2}{7}{Reinforcement learning}{chapter.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Problem setting}{7}{section.2.1}\protected@file@percent }
\newlabel{subsec-problem-setting}{{2.1}{7}{Problem setting}{section.2.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Conceptual schematic of reinforcement learning.\relax }}{7}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rl-shematic}{{2.1}{7}{Conceptual schematic of reinforcement learning.\relax }{figure.caption.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Bandit problems}{7}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Markov Decision Processes}{8}{subsection.2.1.2}\protected@file@percent }
\newlabel{subsec-mdps}{{2.1.2}{8}{Markov Decision Processes}{subsection.2.1.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Schematic of a Markov chain.\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:markov-chain}{{2.2}{8}{Schematic of a Markov chain.\relax }{figure.caption.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Schematic of a Markov decision process.\relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:mdp}{{2.3}{9}{Schematic of a Markov decision process.\relax }{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Schematic of a partially observable Markov decision process.\relax }}{9}{figure.caption.9}\protected@file@percent }
\newlabel{fig:pomdp}{{2.4}{9}{Schematic of a partially observable Markov decision process.\relax }{figure.caption.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Key concepts in reinforcement learning}{9}{section.2.2}\protected@file@percent }
\newlabel{subsec-key-rl-concepts}{{2.2}{9}{Key concepts in reinforcement learning}{section.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Policy}{9}{subsection.2.2.1}\protected@file@percent }
\newlabel{fig:policy-in-mdp}{{\caption@xref {fig:policy-in-mdp}{ on input line 234}}{9}{Policy}{figure.caption.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.1}Goal of reinforcement learning}{10}{subsubsection.2.2.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Value functions}{10}{subsection.2.2.2}\protected@file@percent }
\newlabel{eq:q-function}{{2.5}{10}{Value functions}{equation.2.2.5}{}}
\abx@aux@cite{suttonrlbook}
\abx@aux@segm{0}{0}{suttonrlbook}
\abx@aux@cite{berkleylectures}
\abx@aux@segm{0}{0}{berkleylectures}
\newlabel{eq:value-function}{{2.6}{11}{Value functions}{equation.2.2.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Classes of reinforcement learning algorithms}{11}{section.2.3}\protected@file@percent }
\newlabel{sec-rl-alg-classes}{{2.3}{11}{Classes of reinforcement learning algorithms}{section.2.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Policy gradients}{11}{subsection.2.3.1}\protected@file@percent }
\newlabel{eq:derivative-of-estimated-rl-obj}{{2.12}{11}{Policy gradients}{equation.2.3.12}{}}
\newlabel{eq:derivative-of-estimated-rl-obj}{{2.3.1}{11}{Policy gradients}{equation.2.3.12}{}}
\newlabel{eq:policy-gradient}{{2.13}{11}{Policy gradients}{equation.2.3.13}{}}
\newlabel{eq:estimated-policy-gradient}{{2.14}{12}{Policy gradients}{equation.2.3.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.1}Baselines}{12}{subsubsection.2.3.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.2}Off-policy gradients}{12}{subsubsection.2.3.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.3}Advanced policy gradients}{13}{subsubsection.2.3.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Actor-critic algorithms}{13}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Value function methods}{15}{subsection.2.3.3}\protected@file@percent }
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\abx@aux@cite{mnih2015humanlevel}
\abx@aux@segm{0}{0}{mnih2015humanlevel}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.1}Dynamic programming}{16}{subsubsection.2.3.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Deep Q-networks and their extensions}{16}{section.2.4}\protected@file@percent }
\newlabel{sec-drl}{{2.4}{16}{Deep Q-networks and their extensions}{section.2.4}{}}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Double Deep Q-networks: DDQN}{17}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Prioritized replay}{17}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Dueling Network}{17}{subsection.2.4.3}\protected@file@percent }
\abx@aux@cite{rainbow}
\abx@aux@segm{0}{0}{rainbow}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Multi-step learning}{18}{subsection.2.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Noisy Nets}{18}{subsection.2.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.6}Integrated Agent:Rainbow}{18}{subsection.2.4.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.7}Deep autoencoders}{18}{subsection.2.4.7}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Problems with RL}{19}{section.2.5}\protected@file@percent }
\newlabel{sec-rl-problems}{{2.5}{19}{Problems with RL}{section.2.5}{}}
\abx@aux@cite{srloverview}
\abx@aux@segm{0}{0}{srloverview}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}State representation learning}{21}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-srl-background}{{3}{21}{State representation learning}{chapter.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Representation models in general}{22}{section.3.1}\protected@file@percent }
\newlabel{sec-repr-models-general}{{3.1}{22}{Representation models in general}{section.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Generative models}{23}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.1}Probabilistic models}{23}{subsubsection.3.1.1.1}\protected@file@percent }
\newlabel{subsub-probabilistic-models}{{3.1.1.1}{23}{Probabilistic models}{subsubsection.3.1.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.2}Directed graphical models}{23}{subsubsection.3.1.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.3}Directly learning a parametric map from input to representation}{24}{subsubsection.3.1.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Discriminative models}{24}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Common representation learning approaches}{25}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.1}Deterministic autoencoders}{25}{subsubsection.3.1.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.2}Variational autoencoders}{25}{subsubsection.3.1.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.3}Deterministic autoencoder regularization}{26}{subsubsection.3.1.3.3}\protected@file@percent }
\newlabel{ae-regularization}{{3.1.3.3}{26}{Deterministic autoencoder regularization}{subsubsection.3.1.3.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Representation models for control}{27}{section.3.2}\protected@file@percent }
\newlabel{sec-srl-for-control}{{3.2}{27}{Representation models for control}{section.3.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Autoencoder}{27}{subsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Auto-encoder: learned by reconstructing the observation (one-to-one). The observation is the input and the computed state is the vector at the auto-encoder's bottleneck layer, i.e. is the output of the encoder part of the auto-encoder network. The loss is calculated between the true observation and the reconstructing observation (which is obtained by passing the observation though both the encoder and the decoder).\relax }}{27}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Forward model}{27}{subsection.3.2.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Forward model: predicting the future state from the state-action pair. The loss is computer from comparing the predicted state against the true next state (the states being the learned states). This can also be done directly by predicting the next observation and comparing against it. \relax }}{28}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Inverse model}{28}{subsection.3.2.3}\protected@file@percent }
\abx@aux@cite{watter2015embed}
\abx@aux@segm{0}{0}{watter2015embed}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Inverse model: predicting the action between two consecutive states. The loss is computer from comparing the predicted action between two consecutive states against the true action that was taken by the agent between those two states. (the states being the learned states). \relax }}{29}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Using prior knowledge to constrain the state space}{29}{subsection.3.2.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Using hybring objectives}{29}{subsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Model-based reinforcement learning}{29}{section.3.3}\protected@file@percent }
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\abx@aux@cite{rainbow}
\abx@aux@segm{0}{0}{rainbow}
\abx@aux@cite{agent57}
\abx@aux@segm{0}{0}{agent57}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Related Work}{31}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-related-work}{{4}{31}{Related Work}{chapter.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Reinforcement learning on Atari}{31}{section.4.1}\protected@file@percent }
\abx@aux@cite{ye2021mastering}
\abx@aux@segm{0}{0}{ye2021mastering}
\abx@aux@cite{schrittwieser2020mastering}
\abx@aux@segm{0}{0}{schrittwieser2020mastering}
\abx@aux@cite{rad}
\abx@aux@segm{0}{0}{rad}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{drqv2}
\abx@aux@segm{0}{0}{drqv2}
\abx@aux@cite{rad}
\abx@aux@segm{0}{0}{rad}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{lossisitsownreward}
\abx@aux@segm{0}{0}{lossisitsownreward}
\abx@aux@cite{rlwauxloss}
\abx@aux@segm{0}{0}{rlwauxloss}
\abx@aux@cite{icm}
\abx@aux@segm{0}{0}{icm}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Efforts in increasing efficiency in Atari}{32}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}State representation learning for efficient model-free learning}{32}{section.4.3}\protected@file@percent }
\abx@aux@cite{lange2010deep}
\abx@aux@segm{0}{0}{lange2010deep}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{ghosh2019variational}
\abx@aux@segm{0}{0}{ghosh2019variational}
\abx@aux@cite{slac}
\abx@aux@segm{0}{0}{slac}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{curl}
\abx@aux@segm{0}{0}{curl}
\abx@aux@cite{rakelly2021mutual}
\abx@aux@segm{0}{0}{rakelly2021mutual}
\abx@aux@cite{anand2019unsupervised}
\abx@aux@segm{0}{0}{anand2019unsupervised}
\abx@aux@cite{mazoure2020deep}
\abx@aux@segm{0}{0}{mazoure2020deep}
\abx@aux@cite{grill2020bootstrap}
\abx@aux@segm{0}{0}{grill2020bootstrap}
\abx@aux@cite{schwarzer2020data}
\abx@aux@segm{0}{0}{schwarzer2020data}
\abx@aux@cite{merckling2022exploratory}
\abx@aux@segm{0}{0}{merckling2022exploratory}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Deterministic generative models}{33}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Stochastic generative models}{33}{subsection.4.3.2}\protected@file@percent }
\abx@aux@cite{slac}
\abx@aux@segm{0}{0}{slac}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Discriminative models}{34}{subsection.4.3.3}\protected@file@percent }
\abx@aux@cite{stooke2021decoupling}
\abx@aux@segm{0}{0}{stooke2021decoupling}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Methods}{35}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Formulating our hypotheses}{35}{section.5.1}\protected@file@percent }
\newlabel{sec-hypothesis-reasoning}{{5.1}{35}{Formulating our hypotheses}{section.5.1}{}}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{rainbow}
\abx@aux@segm{0}{0}{rainbow}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Schematic of the feature extractor neural network parameter space. Since unsupervised learning converges much faster, it constricts the search space for the features extracted through reinforcement learning. This constriction is enforced joint training of both unsupervised state representation and reinforcement learning.\relax }}{36}{figure.caption.14}\protected@file@percent }
\newlabel{fig-rl-srl-features-space}{{5.1}{36}{Schematic of the feature extractor neural network parameter space. Since unsupervised learning converges much faster, it constricts the search space for the features extracted through reinforcement learning. This constriction is enforced joint training of both unsupervised state representation and reinforcement learning.\relax }{figure.caption.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Our approach}{36}{section.5.2}\protected@file@percent }
\abx@aux@cite{icm}
\abx@aux@segm{0}{0}{icm}
\abx@aux@cite{rakelly2021mutual}
\abx@aux@segm{0}{0}{rakelly2021mutual}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{ghosh2019variational}
\abx@aux@segm{0}{0}{ghosh2019variational}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{drqv2}
\abx@aux@segm{0}{0}{drqv2}
\abx@aux@cite{bellemare2013arcade}
\abx@aux@segm{0}{0}{bellemare2013arcade}
\abx@aux@cite{exploratorysrl}
\abx@aux@segm{0}{0}{exploratorysrl}
\abx@aux@cite{weng2021tianshou}
\abx@aux@segm{0}{0}{weng2021tianshou}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Environment and Preprocessing}{38}{section.5.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Implementation}{38}{section.5.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Tianshou}{38}{subsection.5.4.1}\protected@file@percent }
\newlabel{tianshou-concepts}{{\caption@xref {tianshou-concepts}{ on input line 286}}{39}{Tianshou}{figure.caption.15}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Tianshou concepts\relax }}{39}{figure.caption.15}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Trainer}{39}{subsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Implementing state representation learning in Tianshou}{40}{subsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.5}Hyperparameters}{40}{section.5.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Results}{41}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{43}{chapter.7}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Bibliography}{45}{chapter.7}\protected@file@percent }
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{lange2010deep}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{bellemare2013arcade}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mnih2013atari}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mnih2015humanlevel}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{watter2015embed}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rlwauxloss}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{lossisitsownreward}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{icm}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rainbow}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{srloverview}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{suttonrlbook}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{anand2019unsupervised}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{ghosh2019variational}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{sac+ae}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{agent57}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{grill2020bootstrap}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{drqv1}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{curl}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rad}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{slac}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mazoure2020deep}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{schrittwieser2020mastering}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{schwarzer2020data}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{berkleylectures}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rakelly2021mutual}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{stooke2021decoupling}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{weng2021tianshou}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{drqv2}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{ye2021mastering}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{merckling2022exploratory}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{exploratorysrl}{ynt/global//global/global}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix 1}{I}{appendix.A}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
