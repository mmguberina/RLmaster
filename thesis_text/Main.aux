\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{ynt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Figures}{xiii}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Tables}{xv}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is reinforcement learning?}{1}{section.1.1}\protected@file@percent }
\newlabel{sec-what-is-rl}{{1.1}{1}{What is reinforcement learning?}{section.1.1}{}}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Why is reinforcement learning interesting?}{2}{section.1.2}\protected@file@percent }
\newlabel{sec-why-is-rl-interesting}{{1.2}{2}{Why is reinforcement learning interesting?}{section.1.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Why learn from pixels?}{2}{section.1.3}\protected@file@percent }
\newlabel{sec-why-pixels}{{1.3}{2}{Why learn from pixels?}{section.1.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.4}Efforts to make reinforcement learning more efficient}{3}{section.1.4}\protected@file@percent }
\newlabel{efforts-in-making-rl-efficient}{{1.4}{3}{Efforts to make reinforcement learning more efficient}{section.1.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Utilizing a world model}{3}{subsection.1.4.1}\protected@file@percent }
\abx@aux@cite{bellemare2013arcade}
\abx@aux@segm{0}{0}{bellemare2013arcade}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Utilizing state representations}{4}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.5}Goal of the thesis}{4}{section.1.5}\protected@file@percent }
\newlabel{sec-thesis-goal}{{1.5}{4}{Goal of the thesis}{section.1.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Hypothesis}{4}{subsection.1.5.1}\protected@file@percent }
\newlabel{subsec-hypothesis}{{1.5.1}{4}{Hypothesis}{subsection.1.5.1}{}}
\newlabel{parallel-training-hypothesis}{{1}{5}{Hypothesis}{Item.1}{}}
\newlabel{good-features-hypothesis}{{2}{5}{Hypothesis}{Item.2}{}}
\newlabel{regularization-hypothesis}{{3}{5}{Hypothesis}{Item.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Contributions}{5}{subsection.1.5.2}\protected@file@percent }
\newlabel{subsec-contributions}{{1.5.2}{5}{Contributions}{subsection.1.5.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.6}Outline}{5}{section.1.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Reinforcement learning}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-rl-background}{{2}{7}{Reinforcement learning}{chapter.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Problem setting}{7}{section.2.1}\protected@file@percent }
\newlabel{subsec-problem-setting}{{2.1}{7}{Problem setting}{section.2.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Conceptual schematic of reinforcement learning.\relax }}{7}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rl-shematic}{{2.1}{7}{Conceptual schematic of reinforcement learning.\relax }{figure.caption.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Bandit problems}{7}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Markov Decision Processes}{8}{subsection.2.1.2}\protected@file@percent }
\newlabel{subsec-mdps}{{2.1.2}{8}{Markov Decision Processes}{subsection.2.1.2}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Schematic of a Markov chain.\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:markov-chain}{{2.2}{8}{Schematic of a Markov chain.\relax }{figure.caption.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Schematic of a Markov decision process.\relax }}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig:mdp}{{2.3}{8}{Schematic of a Markov decision process.\relax }{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Schematic of a partially observable Markov decision process.\relax }}{9}{figure.caption.9}\protected@file@percent }
\newlabel{fig:pomdp}{{2.4}{9}{Schematic of a partially observable Markov decision process.\relax }{figure.caption.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Key concepts in reinforcement learning}{9}{section.2.2}\protected@file@percent }
\newlabel{subsec-key-rl-concepts}{{2.2}{9}{Key concepts in reinforcement learning}{section.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Policy}{9}{subsection.2.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Schematic of a Markov decision process with a policy $ \pi $.\relax }}{10}{figure.caption.10}\protected@file@percent }
\newlabel{fig:policy-in-mdp}{{2.5}{10}{Schematic of a Markov decision process with a policy $ \pi $.\relax }{figure.caption.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Goal of reinforcement learning}{10}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Value functions}{10}{subsection.2.2.3}\protected@file@percent }
\abx@aux@cite{suttonrlbook}
\abx@aux@segm{0}{0}{suttonrlbook}
\abx@aux@cite{berkleylectures}
\abx@aux@segm{0}{0}{berkleylectures}
\newlabel{eq:q-function}{{2.5}{11}{Value functions}{equation.2.2.5}{}}
\newlabel{eq:value-function}{{2.6}{11}{Value functions}{equation.2.2.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Classes of reinforcement learning algorithms}{11}{section.2.3}\protected@file@percent }
\newlabel{sec-rl-alg-classes}{{2.3}{11}{Classes of reinforcement learning algorithms}{section.2.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Policy gradient algorithms}{11}{subsection.2.3.1}\protected@file@percent }
\newlabel{sub-policy-gradient}{{2.3.1}{11}{Policy gradient algorithms}{subsection.2.3.1}{}}
\newlabel{eq:derivative-of-estimated-rl-obj}{{2.12}{11}{Policy gradient algorithms}{equation.2.3.12}{}}
\newlabel{eq:derivative-of-estimated-rl-obj}{{2.3.1}{12}{Policy gradient algorithms}{equation.2.3.12}{}}
\newlabel{eq:policy-gradient}{{2.13}{12}{Policy gradient algorithms}{equation.2.3.13}{}}
\newlabel{eq:estimated-policy-gradient}{{2.14}{12}{Policy gradient algorithms}{equation.2.3.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.1}Baselines}{12}{subsubsection.2.3.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.2}Off-policy gradients}{13}{subsubsection.2.3.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.3}Advanced policy gradients}{14}{subsubsection.2.3.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Actor-critic algorithms}{14}{subsection.2.3.2}\protected@file@percent }
\newlabel{sub-ac-algs}{{2.3.2}{14}{Actor-critic algorithms}{subsection.2.3.2}{}}
\newlabel{eq-n-step-return}{{2.33}{15}{Actor-critic algorithms}{equation.2.3.33}{}}
\abx@aux@cite{suttonrlbook}
\abx@aux@segm{0}{0}{suttonrlbook}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Value function methods}{16}{subsection.2.3.3}\protected@file@percent }
\newlabel{eq-greedy-pi}{{2.35}{16}{Value function methods}{equation.2.3.35}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.1}Dynamic programming}{16}{subsubsection.2.3.3.1}\protected@file@percent }
\newlabel{eq-bellman-value-update}{{2.36}{16}{Dynamic programming}{equation.2.3.36}{}}
\newlabel{alg-finite-value-iteration}{{2.3.3.1}{17}{Dynamic programming}{Item.16}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.2}Fitted value iteration}{17}{subsubsection.2.3.3.2}\protected@file@percent }
\newlabel{eq:fitted_q_iteration_algorithm}{{2.3.3.2}{17}{Fitted value iteration}{subsubsection.2.3.3.2}{}}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Deep reinforcement learning with Q-functions}{18}{section.2.4}\protected@file@percent }
\newlabel{sec-drl}{{2.4}{18}{Deep reinforcement learning with Q-functions}{section.2.4}{}}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\newlabel{q-learning-w-replay-buffer}{{2.4}{19}{Deep reinforcement learning with Q-functions}{section.2.4}{}}
\newlabel{alg-classic-dqn}{{2.4}{19}{Deep reinforcement learning with Q-functions}{Item.25}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Double Q-networks (DDQN)}{20}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Q-learning with multi-step returns}{20}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Prioritized replay}{20}{subsection.2.4.3}\protected@file@percent }
\abx@aux@cite{rainbow}
\abx@aux@segm{0}{0}{rainbow}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Dueling Network}{21}{subsection.2.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.5}Noisy Nets}{21}{subsection.2.4.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.6}Integrated Agent:Rainbow}{21}{subsection.2.4.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.7}Deep autoencoders}{21}{subsection.2.4.7}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Problems with RL}{22}{section.2.5}\protected@file@percent }
\newlabel{sec-rl-problems}{{2.5}{22}{Problems with RL}{section.2.5}{}}
\abx@aux@cite{bengio2013representation}
\abx@aux@segm{0}{0}{bengio2013representation}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}State representation learning}{25}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-srl-background}{{3}{25}{State representation learning}{chapter.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Representation learning in general}{26}{section.3.1}\protected@file@percent }
\newlabel{sec-repr-models-general}{{3.1}{26}{Representation learning in general}{section.3.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Generative models}{27}{subsection.3.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.1}Probabilistic models}{27}{subsubsection.3.1.1.1}\protected@file@percent }
\newlabel{subsub-probabilistic-models}{{3.1.1.1}{27}{Probabilistic models}{subsubsection.3.1.1.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.2}Directed graphical models}{27}{subsubsection.3.1.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1.3}Directly learning a parametric map from input to representation}{27}{subsubsection.3.1.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Discriminative models}{28}{subsection.3.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Common representation learning approaches}{28}{subsection.3.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.1}Deterministic autoencoders}{28}{subsubsection.3.1.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.2}Variational autoencoders}{29}{subsubsection.3.1.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3.3}Deterministic autoencoder regularization}{30}{subsubsection.3.1.3.3}\protected@file@percent }
\newlabel{ae-regularization}{{3.1.3.3}{30}{Deterministic autoencoder regularization}{subsubsection.3.1.3.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Representation models for control}{30}{section.3.2}\protected@file@percent }
\newlabel{sec-srl-for-control}{{3.2}{30}{Representation models for control}{section.3.2}{}}
\abx@aux@cite{srloverview}
\abx@aux@segm{0}{0}{srloverview}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Autoencoder}{31}{subsection.3.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Auto-encoder: learned by reconstructing the observation (one-to-one). The observation is the input and the computed state is the vector at the auto-encoder's bottleneck layer, i.e. is the output of the encoder part of the auto-encoder network. The loss is calculated between the true observation and the reconstructing observation (which is obtained by passing the observation though both the encoder and the decoder).\relax }}{32}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Forward model}{32}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Inverse model}{32}{subsection.3.2.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Forward model: predicting the future state from the state-action pair. The loss is computer from comparing the predicted state against the true next state (the states being the learned states). This can also be done directly by predicting the next observation and comparing against it. \relax }}{33}{figure.caption.12}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Inverse model: predicting the action between two consecutive states. The loss is computer from comparing the predicted action between two consecutive states against the true action that was taken by the agent between those two states. (the states being the learned states). \relax }}{33}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Using prior knowledge to constrain the state space}{33}{subsection.3.2.4}\protected@file@percent }
\abx@aux@cite{watter2015embed}
\abx@aux@segm{0}{0}{watter2015embed}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Using hybring objectives}{34}{subsection.3.2.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}Model-based reinforcement learning}{34}{section.3.3}\protected@file@percent }
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\abx@aux@cite{rainbow}
\abx@aux@segm{0}{0}{rainbow}
\abx@aux@cite{agent57}
\abx@aux@segm{0}{0}{agent57}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Related Work}{35}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-related-work}{{4}{35}{Related Work}{chapter.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Reinforcement learning on Atari}{35}{section.4.1}\protected@file@percent }
\abx@aux@cite{ye2021mastering}
\abx@aux@segm{0}{0}{ye2021mastering}
\abx@aux@cite{schrittwieser2020mastering}
\abx@aux@segm{0}{0}{schrittwieser2020mastering}
\abx@aux@cite{rad}
\abx@aux@segm{0}{0}{rad}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{drqv2}
\abx@aux@segm{0}{0}{drqv2}
\abx@aux@cite{rad}
\abx@aux@segm{0}{0}{rad}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{lossisitsownreward}
\abx@aux@segm{0}{0}{lossisitsownreward}
\abx@aux@cite{rlwauxloss}
\abx@aux@segm{0}{0}{rlwauxloss}
\abx@aux@cite{icm}
\abx@aux@segm{0}{0}{icm}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Efforts in increasing efficiency in Atari}{36}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}State representation learning for efficient model-free learning}{36}{section.4.3}\protected@file@percent }
\abx@aux@cite{lange2010deep}
\abx@aux@segm{0}{0}{lange2010deep}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{ghosh2019variational}
\abx@aux@segm{0}{0}{ghosh2019variational}
\abx@aux@cite{slac}
\abx@aux@segm{0}{0}{slac}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{curl}
\abx@aux@segm{0}{0}{curl}
\abx@aux@cite{rakelly2021mutual}
\abx@aux@segm{0}{0}{rakelly2021mutual}
\abx@aux@cite{anand2019unsupervised}
\abx@aux@segm{0}{0}{anand2019unsupervised}
\abx@aux@cite{mazoure2020deep}
\abx@aux@segm{0}{0}{mazoure2020deep}
\abx@aux@cite{grill2020bootstrap}
\abx@aux@segm{0}{0}{grill2020bootstrap}
\abx@aux@cite{schwarzer2020data}
\abx@aux@segm{0}{0}{schwarzer2020data}
\abx@aux@cite{merckling2022exploratory}
\abx@aux@segm{0}{0}{merckling2022exploratory}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Deterministic generative models}{37}{subsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Stochastic generative models}{37}{subsection.4.3.2}\protected@file@percent }
\abx@aux@cite{slac}
\abx@aux@segm{0}{0}{slac}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Discriminative models}{38}{subsection.4.3.3}\protected@file@percent }
\abx@aux@cite{stooke2021decoupling}
\abx@aux@segm{0}{0}{stooke2021decoupling}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Methods}{39}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}Formulating our hypotheses}{39}{section.5.1}\protected@file@percent }
\newlabel{sec-hypothesis-reasoning}{{5.1}{39}{Formulating our hypotheses}{section.5.1}{}}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{rainbow}
\abx@aux@segm{0}{0}{rainbow}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Schematic of the feature extractor neural network parameter space. Since unsupervised learning converges much faster, it constricts the search space for the features extracted through reinforcement learning. This constriction is enforced joint training of both unsupervised state representation and reinforcement learning.\relax }}{40}{figure.caption.14}\protected@file@percent }
\newlabel{fig-rl-srl-features-space}{{5.1}{40}{Schematic of the feature extractor neural network parameter space. Since unsupervised learning converges much faster, it constricts the search space for the features extracted through reinforcement learning. This constriction is enforced joint training of both unsupervised state representation and reinforcement learning.\relax }{figure.caption.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Our approach}{40}{section.5.2}\protected@file@percent }
\abx@aux@cite{icm}
\abx@aux@segm{0}{0}{icm}
\abx@aux@cite{rakelly2021mutual}
\abx@aux@segm{0}{0}{rakelly2021mutual}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{ghosh2019variational}
\abx@aux@segm{0}{0}{ghosh2019variational}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{drqv2}
\abx@aux@segm{0}{0}{drqv2}
\newlabel{test-ae-fixed}{{1b}{41}{Our approach}{Item.43}{}}
\abx@aux@cite{bellemare2013arcade}
\abx@aux@segm{0}{0}{bellemare2013arcade}
\abx@aux@cite{exploratorysrl}
\abx@aux@segm{0}{0}{exploratorysrl}
\abx@aux@cite{weng2021tianshou}
\abx@aux@segm{0}{0}{weng2021tianshou}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Environment and Preprocessing}{42}{section.5.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.4}Implementation}{42}{section.5.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Tianshou}{42}{subsection.5.4.1}\protected@file@percent }
\newlabel{tianshou-concepts}{{\caption@xref {tianshou-concepts}{ on input line 286}}{43}{Tianshou}{figure.caption.15}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Tianshou concepts\relax }}{43}{figure.caption.15}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Trainer}{43}{subsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Implementing state representation learning in Tianshou}{44}{subsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.5}Hyperparameters}{44}{section.5.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Results}{45}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.1}Testing different training styles on Pong}{45}{section.6.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.2}Multi-game comparison}{45}{section.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {7}Discussion}{47}{chapter.7}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusion}{49}{chapter.8}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Bibliography}{51}{chapter.8}\protected@file@percent }
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{lange2010deep}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{bellemare2013arcade}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{bengio2013representation}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mnih2013atari}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mnih2015humanlevel}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{watter2015embed}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rlwauxloss}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{lossisitsownreward}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{icm}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rainbow}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{srloverview}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{suttonrlbook}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{anand2019unsupervised}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{ghosh2019variational}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{sac+ae}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{agent57}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{grill2020bootstrap}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{drqv1}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{curl}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rad}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{slac}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mazoure2020deep}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{schrittwieser2020mastering}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{schwarzer2020data}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{berkleylectures}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rakelly2021mutual}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{stooke2021decoupling}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{weng2021tianshou}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{drqv2}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{ye2021mastering}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{merckling2022exploratory}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{exploratorysrl}{ynt/global//global/global}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix 1}{I}{appendix.A}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
