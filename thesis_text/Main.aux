\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{ynt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Figures}{xiii}{chapter*.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{List of Tables}{xv}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is reinforcement learning?}{1}{section.1.1}\protected@file@percent }
\newlabel{sec-what-is-rl}{{1.1}{1}{What is reinforcement learning?}{section.1.1}{}}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.2}Why is reinforcement learning interesting?}{2}{section.1.2}\protected@file@percent }
\newlabel{sec-why-is-rl-interesting}{{1.2}{2}{Why is reinforcement learning interesting?}{section.1.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.3}Efforts in making reinforcement learning more efficient}{2}{section.1.3}\protected@file@percent }
\newlabel{efforts-in-making-rl-efficient}{{1.3}{2}{Efforts in making reinforcement learning more efficient}{section.1.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.4}Goal of the thesis}{3}{section.1.4}\protected@file@percent }
\newlabel{sec-thesis-goal}{{1.4}{3}{Goal of the thesis}{section.1.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Hypothesis}{4}{subsection.1.4.1}\protected@file@percent }
\newlabel{subsec-hypothesis}{{1.4.1}{4}{Hypothesis}{subsection.1.4.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Contributions}{5}{subsection.1.4.2}\protected@file@percent }
\newlabel{subsec-contributions}{{1.4.2}{5}{Contributions}{subsection.1.4.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1.5}Outline}{5}{section.1.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-background}{{2}{7}{Background}{chapter.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction to reinforcement learning}{7}{section.2.1}\protected@file@percent }
\newlabel{sec-rl-intro}{{2.1}{7}{Introduction to reinforcement learning}{section.2.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Problem setting}{7}{subsection.2.1.1}\protected@file@percent }
\newlabel{subsec-problem-setting}{{2.1.1}{7}{Problem setting}{subsection.2.1.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Conceptual schematic of reinforcement learning.\relax }}{7}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rl-shematic}{{2.1}{7}{Conceptual schematic of reinforcement learning.\relax }{figure.caption.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Bandit problems}{8}{subsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Markov Decision Processes}{8}{subsection.2.1.3}\protected@file@percent }
\newlabel{subsec-mdps}{{2.1.3}{8}{Markov Decision Processes}{subsection.2.1.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Schematic of a Markov chain.\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:markov-chain}{{2.2}{8}{Schematic of a Markov chain.\relax }{figure.caption.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Schematic of a Markov decision process.\relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:markov-chain}{{2.3}{9}{Schematic of a Markov decision process.\relax }{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Schematic of a partially observable Markov decision process.\relax }}{9}{figure.caption.9}\protected@file@percent }
\newlabel{fig:pomdp}{{2.4}{9}{Schematic of a partially observable Markov decision process.\relax }{figure.caption.9}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Key concepts in reinforcement learning}{9}{subsection.2.1.4}\protected@file@percent }
\newlabel{subsec-key-rl-concepts}{{2.1.4}{9}{Key concepts in reinforcement learning}{subsection.2.1.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.1}Policy}{9}{subsubsection.2.1.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.2}Goal of reinforcement learning}{10}{subsubsection.2.1.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.3}Value functions}{10}{subsubsection.2.1.4.3}\protected@file@percent }
\newlabel{eq:q-function}{{2.5}{10}{Value functions}{equation.2.1.5}{}}
\abx@aux@cite{suttonrlbook}
\abx@aux@segm{0}{0}{suttonrlbook}
\newlabel{eq:value-function}{{2.6}{11}{Value functions}{equation.2.1.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Classes of reinforcement learning algorithms}{11}{section.2.2}\protected@file@percent }
\newlabel{sec-rl-alg-classes}{{2.2}{11}{Classes of reinforcement learning algorithms}{section.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Policy gradients}{11}{subsection.2.2.1}\protected@file@percent }
\newlabel{eq:derivative-of-estimated-rl-obj}{{2.12}{11}{Policy gradients}{equation.2.2.12}{}}
\newlabel{eq:derivative-of-estimated-rl-obj}{{2.2.1}{11}{Policy gradients}{equation.2.2.12}{}}
\newlabel{eq:policy-gradient}{{2.13}{11}{Policy gradients}{equation.2.2.13}{}}
\newlabel{eq:estimated-policy-gradient}{{2.14}{12}{Policy gradients}{equation.2.2.14}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.1}Baselines}{12}{subsubsection.2.2.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.2}Off-policy gradients}{12}{subsubsection.2.2.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1.3}Advanced policy gradients}{13}{subsubsection.2.2.1.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Actor-critic algorithms}{13}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Value function methods}{15}{subsection.2.2.3}\protected@file@percent }
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\abx@aux@cite{mnih2015humanlevel}
\abx@aux@segm{0}{0}{mnih2015humanlevel}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.1}Dynamic programming}{16}{subsubsection.2.2.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Deep Reinforcement Learning and DQN}{16}{section.2.3}\protected@file@percent }
\newlabel{sec-drl}{{2.3}{16}{Deep Reinforcement Learning and DQN}{section.2.3}{}}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Extension of DQN }{17}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.1}Double Deep Q-networks: DDQN}{17}{subsubsection.2.3.1.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.2}Prioritized replay}{17}{subsubsection.2.3.1.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.3}Dueling Network}{17}{subsubsection.2.3.1.3}\protected@file@percent }
\abx@aux@cite{raibow}
\abx@aux@segm{0}{0}{raibow}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.4}Multi-step learning}{18}{subsubsection.2.3.1.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.5}Noisy Nets}{18}{subsubsection.2.3.1.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1.6}Integrated Agent:Rainbow}{18}{subsubsection.2.3.1.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Deep autoencoders}{18}{subsection.2.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Problems with RL}{20}{section.2.4}\protected@file@percent }
\newlabel{sec-rl-problems}{{2.4}{20}{Problems with RL}{section.2.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Unsupervised learning on images}{20}{section.2.5}\protected@file@percent }
\abx@aux@cite{srloverview}
\abx@aux@segm{0}{0}{srloverview}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.6}Introduction to state learning learning}{21}{section.2.6}\protected@file@percent }
\newlabel{sec-srl-intro}{{2.6}{21}{Introduction to state learning learning}{section.2.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Representation models in general}{22}{subsection.2.6.1}\protected@file@percent }
\newlabel{sub-repr-models-general}{{2.6.1}{22}{Representation models in general}{subsection.2.6.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Generative models}{23}{subsection.2.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.1}Probabilistic models}{23}{subsubsection.2.6.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.2}Directed graphical models}{23}{subsubsection.2.6.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2.3}Directly learning a parametric map from input to representation}{23}{subsubsection.2.6.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Discriminative models}{24}{subsection.2.6.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Common representation learning approaches}{24}{subsection.2.6.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.4.1}Deterministic autoencoders}{24}{subsubsection.2.6.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.4.2}Variational autoencoders}{25}{subsubsection.2.6.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.4.3}Deterministic autoencoder regularization}{26}{subsubsection.2.6.4.3}\protected@file@percent }
\newlabel{ae-regularization}{{2.6.4.3}{26}{Deterministic autoencoder regularization}{subsubsection.2.6.4.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.5}Representation models for control}{26}{subsection.2.6.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.6}Autoencoder}{26}{subsection.2.6.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Auto-encoder: learned by reconstructing the observation (one-to-one). The observation is the input and the computed state is the vector at the auto-encoder's bottleneck layer, i.e. is the output of the encoder part of the auto-encoder network. The loss is calculated between the true observation and the reconstructing observation (which is obtained by passing the observation though both the encoder and the decoder).\relax }}{27}{figure.caption.11}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.7}Forward model}{27}{subsection.2.6.7}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Forward model: predicting the future state from the state-action pair. The loss is computer from comparing the predicted state against the true next state (the states being the learned states). This can also be done directly by predicting the next observation and comparing against it. \relax }}{28}{figure.caption.12}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.8}Inverse model}{28}{subsection.2.6.8}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Inverse model: predicting the action between two consecutive states. The loss is computer from comparing the predicted action between two consecutive states against the true action that was taken by the agent between those two states. (the states being the learned states). \relax }}{28}{figure.caption.13}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.9}Using prior knowledge to constrain the state space}{29}{subsection.2.6.9}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.10}Using hybring objectives}{29}{subsection.2.6.10}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.7}Model-based reinforcement learning}{29}{section.2.7}\protected@file@percent }
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{mnih2013atari}
\abx@aux@segm{0}{0}{mnih2013atari}
\abx@aux@cite{rainbow}
\abx@aux@segm{0}{0}{rainbow}
\abx@aux@cite{agent57}
\abx@aux@segm{0}{0}{agent57}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related Work}{31}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch-related-work}{{3}{31}{Related Work}{chapter.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.1}Reinforcement learning on Atari}{31}{section.3.1}\protected@file@percent }
\abx@aux@cite{ye2021mastering}
\abx@aux@segm{0}{0}{ye2021mastering}
\abx@aux@cite{schrittwieser2020mastering}
\abx@aux@segm{0}{0}{schrittwieser2020mastering}
\abx@aux@cite{rad}
\abx@aux@segm{0}{0}{rad}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{drqv2}
\abx@aux@segm{0}{0}{drqv2}
\abx@aux@cite{rad}
\abx@aux@segm{0}{0}{rad}
\abx@aux@cite{drqv1}
\abx@aux@segm{0}{0}{drqv1}
\abx@aux@cite{lossisitsownreward}
\abx@aux@segm{0}{0}{lossisitsownreward}
\abx@aux@cite{rlwauxloss}
\abx@aux@segm{0}{0}{rlwauxloss}
\abx@aux@cite{icm}
\abx@aux@segm{0}{0}{icm}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.2}Efforts in increasing efficiency in Atari}{32}{section.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.3}State representation learning for efficient model-free learning}{32}{section.3.3}\protected@file@percent }
\abx@aux@cite{lange2010deep}
\abx@aux@segm{0}{0}{lange2010deep}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\abx@aux@cite{ghosh2019variational}
\abx@aux@segm{0}{0}{ghosh2019variational}
\abx@aux@cite{slac}
\abx@aux@segm{0}{0}{slac}
\abx@aux@cite{sac+ae}
\abx@aux@segm{0}{0}{sac+ae}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Deterministic generative models}{33}{subsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Stochastic generative models}{33}{subsection.3.3.2}\protected@file@percent }
\abx@aux@cite{curl}
\abx@aux@segm{0}{0}{curl}
\abx@aux@cite{rakelly2021mutual}
\abx@aux@segm{0}{0}{rakelly2021mutual}
\abx@aux@cite{anand2019unsupervised}
\abx@aux@segm{0}{0}{anand2019unsupervised}
\abx@aux@cite{mazoure2020deep}
\abx@aux@segm{0}{0}{mazoure2020deep}
\abx@aux@cite{grill2020bootstrap}
\abx@aux@segm{0}{0}{grill2020bootstrap}
\abx@aux@cite{schwarzer2020data}
\abx@aux@segm{0}{0}{schwarzer2020data}
\abx@aux@cite{merckling2022exploratory}
\abx@aux@segm{0}{0}{merckling2022exploratory}
\abx@aux@cite{slac}
\abx@aux@segm{0}{0}{slac}
\abx@aux@cite{investigationontheDeepLearningFramework}
\abx@aux@segm{0}{0}{investigationontheDeepLearningFramework}
\abx@aux@cite{auto-encoderforEfficientEmbeddedReinforcementLearning}
\abx@aux@segm{0}{0}{auto-encoderforEfficientEmbeddedReinforcementLearning}
\abx@aux@cite{firstaeinrl}
\abx@aux@segm{0}{0}{firstaeinrl}
\abx@aux@cite{sac}
\abx@aux@segm{0}{0}{sac}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Discriminative models}{34}{subsection.3.3.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Rainbow stuff}{34}{subsection.3.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3.4}Formulating our hypothesis}{35}{section.3.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Methods}{37}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Problems to be tackled}{37}{section.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}Hypotheses}{37}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Enviroment and Preprocessing}{38}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Deep Auto-encoder and Model Architecture}{38}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Training the RL Agent}{38}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Results}{41}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.1}Two Step Training}{41}{subsection.5.0.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.0.2}Parallel Training}{41}{subsection.5.0.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{43}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.1}Discussion}{43}{section.6.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6.2}Conclusion}{43}{section.6.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Bibliography}{45}{section.6.2}\protected@file@percent }
\blx@aux@read@bbl@mdfivesum{563540C53007CED7A6D09F66ED05CF23}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{firstaeinrl}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mnih2013atari}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{mnih2015humanlevel}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rlwauxloss}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{lossisitsownreward}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{icm}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{sac}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rainbow}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{suttonrlbook}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{sac+ae}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{agent57}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{drqv1}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{curl}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{rad}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{laser}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{drqv2}{ynt/global//global/global}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix 1}{I}{appendix.A}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
