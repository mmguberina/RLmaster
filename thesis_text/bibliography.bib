@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Malaysia; Pearson Education Limited,}
} 

@article{mnih2013atari,
  added-at = {2019-07-12T20:11:01.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  biburl = {https://www.bibsonomy.org/bibtex/2a00ec4c09f5dc9b3f8a1836f4e02bb5d/lanteunis},
  interhash = {78966703f649bae69a08a6a23a4e8879},
  intrahash = {a00ec4c09f5dc9b3f8a1836f4e02bb5d},
  keywords = {},
  note = {cite arxiv:1312.5602Comment: NIPS Deep Learning Workshop 2013},
  timestamp = {2019-07-12T20:11:01.000+0200},
  title = {Playing Atari with Deep Reinforcement Learning},
  url = {http://arxiv.org/abs/1312.5602},
  year = 2013
}


@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  url = {http://dx.doi.org/10.1038/nature14236},
  volume = 518,
  year = 2015
}

@inproceedings{Doubleq-learning-16,
    author = {Hasselt, Hado van and Guez, Arthur and Silver, David},
    title = {Deep Reinforcement Learning with Double Q-Learning},
    year = {2016},
    publisher = {AAAI Press},
    booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
    pages = {2094–2100},
    numpages = {7},
    location = {Phoenix, Arizona},
    series = {AAAI'16}
    }
    
@inproceedings{Doubleq-learning-10,
    author = {Hasselt, Hado van},
    title = {Double Q-Learning},
    year = {2010},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    pages = {2613–2621},
    numpages = {9},
    location = {Vancouver, British Columbia, Canada},
    series = {NIPS'10}
}

@inproceedings{duelingnetworkarchitectures,
    author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
    title = {Dueling Network Architectures for Deep Reinforcement Learning},
    year = {2016},
    publisher = {JMLR.org},
    booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
    pages = {1995–2003},
    numpages = {9},
    location = {New York, NY, USA},
    series = {ICML'16}
}

@inproceedings{Yi2018ModelbasedRL,
  title={Model-based reinforcement learning: A survey},
  author={Fengji Yi and Wenlong Fu and Huan Liang},
  year={2018}
}

@book{puterman2014markov,
  added-at = {2017-04-07T12:13:11.000+0200},
  author = {Puterman, Martin L},
  biburl = {https://www.bibsonomy.org/bibtex/22e7ac99cd30c4892171e5a7cef1bc7a7/becker},
  interhash = {6cec8f775a265d8741171d17e4a4e7d0},
  intrahash = {2e7ac99cd30c4892171e5a7cef1bc7a7},
  keywords = {inthesis diss markov chain decision process citedby:scholar:count:9594 citedby:scholar:timestamp:2017-4-7},
  publisher = {John Wiley \& Sons},
  timestamp = {2017-04-07T12:13:11.000+0200},
  title = {Markov decision processes: discrete stochastic dynamic programming},
  year = 2014
}

@inproceedings{NEURIPS2020_f7efa4f8,
     author = {Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
     booktitle = {Advances in Neural Information Processing Systems},
     editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
     pages = {21810--21823},
     publisher = {Curran Associates, Inc.},
     title = {MOReL: Model-Based Offline Reinforcement Learning},
     url = {https://proceedings.neurips.cc/paper/2020/file/f7efa4f864ae9b88d43527f4b14f750f-Paper.pdf},
     volume = {33},
     year = {2020}
}

@inproceedings{gehring2017convolutional,
  title={Convolutional sequence to sequence learning},
  author={Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
  booktitle={International Conference on Machine Learning},
  pages={1243--1252},
  year={2017},
  organization={PMLR}
}

@article{DBLP:journals/corr/Zhou15c,
  author    = {Li Zhou},
  title     = {A Survey on Contextual Multi-armed Bandits},
  journal   = {CoRR},
  volume    = {abs/1508.03326},
  year      = {2015},
  url       = {http://arxiv.org/abs/1508.03326},
  eprinttype = {arXiv},
  eprint    = {1508.03326},
  timestamp = {Sun, 06 Sep 2020 22:24:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Zhou15c.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{sac,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}
@inproceedings{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-second AAAI conference on artificial intelligence},
  year={2018}
}

@article{sac+ae,
  title={Improving sample efficiency in model-free reinforcement learning from images},
  author={Yarats, Denis and Zhang, Amy and Kostrikov, Ilya and Amos, Brandon and Pineau, Joelle and Fergus, Rob},
  journal={arXiv preprint arXiv:1910.01741},
  year={2019}
}

@inproceedings{laser,
  title={Laser: Learning a latent action space for efficient reinforcement learning},
  author={Allshire, Arthur and Mart{\'\i}n-Mart{\'\i}n, Roberto and Lin, Charles and Manuel, Shawn and Savarese, Silvio and Garg, Animesh},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6650--6656},
  year={2021},
  organization={IEEE}
}
@inproceedings{icm,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

@article{rad,
  title={Reinforcement learning with augmented data},
  author={Laskin, Misha and Lee, Kimin and Stooke, Adam and Pinto, Lerrel and Abbeel, Pieter and Srinivas, Aravind},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={19884--19895},
  year={2020}
}

@inproceedings{curl,
  title={Curl: Contrastive unsupervised representations for reinforcement learning},
  author={Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={5639--5650},
  year={2020},
  organization={PMLR}
}

@article{drqv2,
  title={Mastering visual continuous control: Improved data-augmented reinforcement learning},
  author={Yarats, Denis and Fergus, Rob and Lazaric, Alessandro and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2107.09645},
  year={2021}
}

@article{lossisitsownreward,
  title={Loss is its own reward: Self-supervision for reinforcement learning},
  author={Shelhamer, Evan and Mahmoudieh, Parsa and Argus, Max and Darrell, Trevor},
  journal={arXiv preprint arXiv:1612.07307},
  year={2016}
}

@inproceedings{agent57,
  title={Agent57: Outperforming the atari human benchmark},
  author={Badia, Adri{\`a} Puigdom{\`e}nech and Piot, Bilal and Kapturowski, Steven and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Zhaohan Daniel and Blundell, Charles},
  booktitle={International Conference on Machine Learning},
  pages={507--517},
  year={2020},
  organization={PMLR}
}
@inproceedings{firstaeinrl,
  title={Deep auto-encoder neural networks in reinforcement learning},
  author={Lange, Sascha and Riedmiller, Martin},
  booktitle={The 2010 international joint conference on neural networks (IJCNN)},
  pages={1--8},
  year={2010},
  organization={IEEE}
}

@article{flow,
  title={Reinforcement learning with latent flow},
  author={Shang, Wenling and Wang, Xiaofei and Srinivas, Aravind and Rajeswaran, Aravind and Gao, Yang and Abbeel, Pieter and Laskin, Misha},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{imageaugmentationisallyouneed,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{srloverview,
  title={State representation learning for control: An overview},
  author={Lesort, Timoth{\'e}e and D{\'\i}az-Rodr{\'\i}guez, Natalia and Goudou, Jean-Franois and Filliat, David},
  journal={Neural Networks},
  volume={108},
  pages={379--392},
  year={2018},
  publisher={Elsevier}
}

@article{drqv1,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{rlwauxloss,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{invariantrepwithoutreconstruction,
  title={Learning invariant representations for reinforcement learning without reconstruction},
  author={Zhang, Amy and McAllister, Rowan and Calandra, Roberto and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.10742},
  year={2020}
}

@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Malaysia; Pearson Education Limited,}
} 

@article{mnih2013atari,
  added-at = {2019-07-12T20:11:01.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  biburl = {https://www.bibsonomy.org/bibtex/2a00ec4c09f5dc9b3f8a1836f4e02bb5d/lanteunis},
  interhash = {78966703f649bae69a08a6a23a4e8879},
  intrahash = {a00ec4c09f5dc9b3f8a1836f4e02bb5d},
  keywords = {},
  note = {cite arxiv:1312.5602Comment: NIPS Deep Learning Workshop 2013},
  timestamp = {2019-07-12T20:11:01.000+0200},
  title = {Playing Atari with Deep Reinforcement Learning},
  url = {http://arxiv.org/abs/1312.5602},
  year = 2013
}


@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  url = {http://dx.doi.org/10.1038/nature14236},
  volume = 518,
  year = 2015
}

@inproceedings{Doubleq-learning-16,
    author = {Hasselt, Hado van and Guez, Arthur and Silver, David},
    title = {Deep Reinforcement Learning with Double Q-Learning},
    year = {2016},
    publisher = {AAAI Press},
    booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
    pages = {2094–2100},
    numpages = {7},
    location = {Phoenix, Arizona},
    series = {AAAI'16}
    }
    
@inproceedings{Doubleq-learning-10,
    author = {Hasselt, Hado van},
    title = {Double Q-Learning},
    year = {2010},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    pages = {2613–2621},
    numpages = {9},
    location = {Vancouver, British Columbia, Canada},
    series = {NIPS'10}
}

@inproceedings{duelingnetworkarchitectures,
    author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
    title = {Dueling Network Architectures for Deep Reinforcement Learning},
    year = {2016},
    publisher = {JMLR.org},
    booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
    pages = {1995–2003},
    numpages = {9},
    location = {New York, NY, USA},
    series = {ICML'16}
}

@inproceedings{Yi2018ModelbasedRL,
  title={Model-based reinforcement learning: A survey},
  author={Fengji Yi and Wenlong Fu and Huan Liang},
  year={2018}
}

@book{puterman2014markov,
  added-at = {2017-04-07T12:13:11.000+0200},
  author = {Puterman, Martin L},
  biburl = {https://www.bibsonomy.org/bibtex/22e7ac99cd30c4892171e5a7cef1bc7a7/becker},
  interhash = {6cec8f775a265d8741171d17e4a4e7d0},
  intrahash = {2e7ac99cd30c4892171e5a7cef1bc7a7},
  keywords = {inthesis diss markov chain decision process citedby:scholar:count:9594 citedby:scholar:timestamp:2017-4-7},
  publisher = {John Wiley \& Sons},
  timestamp = {2017-04-07T12:13:11.000+0200},
  title = {Markov decision processes: discrete stochastic dynamic programming},
  year = 2014
}

@inproceedings{NEURIPS2020_f7efa4f8,
     author = {Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
     booktitle = {Advances in Neural Information Processing Systems},
     editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
     pages = {21810--21823},
     publisher = {Curran Associates, Inc.},
     title = {MOReL: Model-Based Offline Reinforcement Learning},
     url = {https://proceedings.neurips.cc/paper/2020/file/f7efa4f864ae9b88d43527f4b14f750f-Paper.pdf},
     volume = {33},
     year = {2020}
}


@article{tdlearning,
author = {Tesauro, Gerald},
title = {Temporal Difference Learning and TD-Gammon},
year = {1995},
issue_date = {March 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/203330.203343},
doi = {10.1145/203330.203343},
journal = {Commun. ACM},
month = {mar},
pages = {58–68},
numpages = {11}
}

@article{drqv1,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{rlwauxloss,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{invariantrepwithoutreconstruction,
  title={Learning invariant representations for reinforcement learning without reconstruction},
  author={Zhang, Amy and McAllister, Rowan and Calandra, Roberto and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.10742},
  year={2020}
}

@ARTICLE{exploratorysrl,
AUTHOR={Merckling, Astrid and Perrin-Gilbert, Nicolas and Coninx, Alex and Doncieux, Stéphane},   
TITLE={Exploratory State Representation Learning},      
JOURNAL={Frontiers in Robotics and AI},      
VOLUME={9},      
YEAR={2022},      
URL={https://www.frontiersin.org/article/10.3389/frobt.2022.762051},       
DOI={10.3389/frobt.2022.762051},      
ISSN={2296-9144}   
}
   
@article{DeepAEforReinforcement,
  author    = {Bharat Prakash and
               Mark Horton and
               Nicholas R. Waytowich and
               William David Hairston and
               Tim Oates and
               Tinoosh Mohsenin},
  title     = {On the use of Deep Autoencoders for Efficient Embedded Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1903.10404},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.10404},
  eprinttype = {arXiv},
  eprint    = {1903.10404},
  timestamp = {Mon, 01 Apr 2019 14:07:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-10404.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ye2021mastering,
  title={Mastering atari games with limited data},
  author={Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

@inproceedings{lange2010deep,
  title={Deep auto-encoder neural networks in reinforcement learning},
  author={Lange, Sascha and Riedmiller, Martin},
  booktitle={The 2010 international joint conference on neural networks (IJCNN)},
  pages={1--8},
  year={2010},
  organization={IEEE}
}

@article{ghosh2019variational,
  title={From variational to deterministic autoencoders},
  author={Ghosh, Partha and Sajjadi, Mehdi SM and Vergari, Antonio and Black, Michael and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1903.12436},
  year={2019}
}

@article{rakelly2021mutual,
  title={Which Mutual-Information Representation Learning Objectives are Sufficient for Control?},
  author={Rakelly, Kate and Gupta, Abhishek and Florensa, Carlos and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{anand2019unsupervised,
  title={Unsupervised state representation learning in atari},
  author={Anand, Ankesh and Racah, Evan and Ozair, Sherjil and Bengio, Yoshua and C{\^o}t{\'e}, Marc-Alexandre and Hjelm, R Devon},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{mazoure2020deep,
  title={Deep reinforcement and infomax learning},
  author={Mazoure, Bogdan and Tachet des Combes, Remi and Doan, Thang Long and Bachman, Philip and Hjelm, R Devon},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3686--3698},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={21271--21284},
  year={2020}
}

@article{merckling2022exploratory,
  title={Exploratory State Representation Learning},
  author={Merckling, Astrid and Perrin-Gilbert, Nicolas and Coninx, Alex and Doncieux, St{\'e}phane},
  journal={Frontiers in Robotics and AI},
  volume={9},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{schwarzer2020data,
  title={Data-efficient reinforcement learning with self-predictive representations},
  author={Schwarzer, Max and Anand, Ankesh and Goel, Rishab and Hjelm, R Devon and Courville, Aaron and Bachman, Philip},
  journal={arXiv preprint arXiv:2007.05929},
  year={2020}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{weng2021tianshou,
  title={Tianshou: A Highly Modularized Deep Reinforcement Learning Library},
  author={Weng, Jiayi and Chen, Huayu and Yan, Dong and You, Kaichao and Duburcq, Alexis and Zhang, Minghao and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2107.14171},
  year={2021}
}
