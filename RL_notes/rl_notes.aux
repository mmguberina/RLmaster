\relax 
\@writefile{toc}{\contentsline {section}{\numberline {0.1}Plan}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Update}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Purpose}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Berkley AI class}{2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Immitation learning}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Formal setting}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Markov chain}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Markov decision process}{2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.3}Partially observed Markov decision process}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{The goal of reinforcement learning}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Note}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.4}Value functions}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition: Q-function}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Definition: value function}{4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Policy gradients}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The idea}{5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Reducing variance}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Causality}{7}\protected@file@percent }
\newlabel{eq:reward_to_go}{{1.30}{7}}
\@writefile{toc}{\contentsline {subsubsection}{Baselines}{7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Off-policy gradients}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Importance sampling}{9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Policy gradient with automatic differentiation}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Policy gradients in practice}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Advanced policy gradients}{11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Actor-critic algorithms}{12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Policy evaluation}{13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}From evaluation to actor-critic}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Aside: discount factors}{15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Actor-critic design choises}{16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Online actor-critic in practise}{16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.6}Critics as state-dependent baselines}{18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Eligibility traces and n-step returns}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Generalied advantage estimation (GAE)}{19}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Value function methods}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Can we omit policy gradient completely?}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Policy iteration}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Dynamic programming}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Policy iteration with dynamic programming}{20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Even simpler dynamic programming}{20}\protected@file@percent }
